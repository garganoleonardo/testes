{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep \n",
    "from random import random\n",
    "\n",
    "\n",
    "import json\n",
    "import urllib.request\n",
    "base_url = 'http://www.portaldatransparencia.gov.br/'\n",
    "\n",
    "def read_table(table):\n",
    "    rows = table.findAll(\"tr\")\n",
    "    header = rows[0]\n",
    "    #print ('header')\n",
    "    cols = header.findAll('th')\n",
    "    #print ('# of cols' + str(len(cols)))\n",
    "\n",
    "    my_json = []\n",
    "    \n",
    "    #for col in cols:\n",
    "        #print (col.getText().strip())\n",
    "\n",
    "    for row in range(1,len(rows)):\n",
    "        my_dict = {}\n",
    "        \n",
    "        a = 'row ' + str(row)\n",
    "        cols = rows[row].findAll(\"td\", {\"class\":\"firstChild\"})\n",
    "        cols_valor = rows[row].findAll(\"td\", {\"class\":\"colunaValor\"})\n",
    "        for col in cols:\n",
    "            for col2 in cols_valor:\n",
    "                b = col2.getText().strip()\n",
    "            c = col.getText().strip()\n",
    "        \n",
    "        \n",
    "        mes_ano = c.split('/')\n",
    "        my_dict['Mes'] = mes_ano[0]\n",
    "        my_dict['Ano'] = int(mes_ano[1])\n",
    "        my_dict['Valor'] = float(b.replace(\".\", \"\").replace(\",00\", \".00\"))\n",
    "        my_json.append(my_dict)\n",
    "    \n",
    "    return my_json\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "def read_person(person_url):\n",
    "    print ('read_person')\n",
    "    print (person_url)\n",
    "    person = urllib.request.urlopen(person_url)\n",
    "    person_soup = BeautifulSoup(person, \"lxml\")\n",
    "\n",
    "    tables = person_soup.findAll(\"table\")\n",
    "    g = read_table(tables[1])\n",
    "    #print (json.dumps(g, indent=2, sort_keys=True, ensure_ascii=False))\n",
    "    return g\n",
    "    \n",
    "    \n",
    "#read_person('http://www.portaldatransparencia.gov.br/PortalTransparenciaPesquisaAcaoDetalhado.asp?Exercicio=2016&textoPesquisa=&textoPesquisaAcao=&codigoAcao=8442&codigoFuncao=08&siglaEstado=AC&codigoMunicipio=0643&codFavorecido=6296326&cpfcnpjnis=00016167611395')\n",
    "\n",
    "#read_person('http://www.portaldatransparencia.gov.br/PortalTransparenciaPesquisaAcaoDetalhado.asp?Exercicio=2016&textoPesquisa=&textoPesquisaAcao=&codigoAcao=8442&codigoFuncao=08&siglaEstado=AC&codigoMunicipio=0157&codFavorecido=4284887&cpfcnpjnis=00021230735463')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import json\n",
    "def read_json(estado,municipio,pagina,nis):\n",
    "    cliente = MongoClient('localhost', 27017)\n",
    "    banco = cliente.projeto_final\n",
    "    projeto_transparencia = banco.test_collection\n",
    "    users = banco.projeto_transparencia\n",
    "    vazio = users.find({}).count()\n",
    "    if vazio != 0: #pro caso do banco estar vazio \n",
    "        a = users.find_one({\"NIS\": nis ,\"Município\" : municipio  })\n",
    "        json_pause = {}\n",
    "        if a is None :\n",
    "            json_pause['Pagina'] = int(pagina)\n",
    "            json_pause['Estado'] = estado\n",
    "            json_pause['Municipio'] = municipio\n",
    "            json_pause['Nis'] = nis\n",
    "            with open('teste_acrelandia.json', 'w') as arquivo:\n",
    "                json.dump(json_pause, arquivo, indent=4, sort_keys=True)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def verifica_pagina():\n",
    "    with open('teste_acrelandia.json', 'r') as arquivo:\n",
    "        json_pause = json.loads(arquivo.read())\n",
    "    return json_pause\n",
    "\n",
    "def verifica_municipio(estado,municipio):\n",
    "    with open('teste_acrelandia.json', 'r') as arquivo:\n",
    "        json_pauses = json.loads(arquivo.read())\n",
    "    #if estado is not None:\n",
    "        if json_pauses[\"Municipio\"] != municipio:\n",
    "            json_pause= {}\n",
    "            json_pause['Pagina'] = 1\n",
    "            json_pause['Estado'] = estado\n",
    "            json_pause['Municipio'] = municipio\n",
    "            json_pause['Nis'] = \"\"\n",
    "            #json_pause['Lido_Municipio'] = json_pauses[\"Municipio\"]\n",
    "            with open('teste_acrelandia.json', 'w') as arquivo:\n",
    "                json.dump(json_pause, arquivo, indent=4, sort_keys=True)\n",
    "            return json_pause\n",
    "        else:\n",
    "            return json_pauses\n",
    "    #else: \n",
    "        #g =[]     \n",
    "        #f = municipio\n",
    "        #g.append(f)\n",
    "        #return g \n",
    "    \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def read_city(city_url):\n",
    "    print (city_url)\n",
    "    b = []\n",
    "    c = []\n",
    "    d = {}\n",
    "    city_page = urllib.request.urlopen(city_url)\n",
    "    city_page_soup = BeautifulSoup(city_page, \"lxml\")\n",
    "    y = city_page_soup.findAll(\"tr\")\n",
    "    w = y[3]\n",
    "    e = w.findAll('td')\n",
    "    f = e[0]\n",
    "    g = f.find('b')\n",
    "    estado = g.getText()\n",
    "    print (estado)\n",
    "    k = y[6]\n",
    "    t = k.findAll('td')\n",
    "    l = t[0]\n",
    "    #q = l.getText()\n",
    "    q = l.find('b')\n",
    "    municipio = q.getText()\n",
    "    print (municipio)\n",
    "    city_pagination = city_page_soup.find(id='paginacao').p.getText()\n",
    "    print(city_pagination)\n",
    "    city_pages = str.split(city_pagination, '/')[1]\n",
    "    #print (city_pages) #total de páginas\n",
    "    npages = int(city_pages)+1\n",
    "    #with open('teste_acrelandia.json', 'w') as arquivo:\n",
    "    cont = 0\n",
    "    for city_page in range(1,npages):\n",
    "        json_pause = verifica_pagina()\n",
    "        json_municipio = verifica_municipio(estado,municipio)\n",
    "        if json_pause[\"Pagina\"] != json_municipio[\"Pagina\"]:\n",
    "            pagina = json_municipio[\"Pagina\"]\n",
    "        else:\n",
    "            pagina = json_pause[\"Pagina\"]\n",
    "        if pagina <= city_page:  \n",
    "            city_page_url = city_url + '&Pagina=' + str(city_page)\n",
    "            pagina = '\\nPAGINA ' + str(city_page)\n",
    "            print (pagina)\n",
    "            a = read_city_page(city_page_url,municipio,estado,city_page)\n",
    "                #d['pagina '+ str(city_page)] = a\n",
    "                    #sleep(1+random())\n",
    "        else:\n",
    "            print (\"Página \" + str(city_page) + \" já lida\")\n",
    "            cont = cont + 1\n",
    "            print (cont)\n",
    "                    #d[\"total_de_paginas\"] = city_page\n",
    "                    #json.dump(d, arquivo, indent=4, sort_keys=True)\n",
    "             \n",
    "            \n",
    "#read_city('http://www.portaldatransparencia.gov.br/PortalTransparenciaPesquisaAcaoFavorecido.asp?Exercicio=2016&textoPesquisa=&textoPesquisaAcao=&codigoAcao=8442&codigoFuncao=08&siglaEstado=AC&codigoMunicipio=0643')\n",
    "#read_city('http://www.portaldatransparencia.gov.br/PortalTransparenciaPesquisaAcaoFavorecido.asp?Exercicio=2016&textoPesquisa=&textoPesquisaAcao=&codigoAcao=8442&codigoFuncao=08&siglaEstado=AC&codigoMunicipio=0157')\n",
    "#read_city('http://www.portaldatransparencia.gov.br/PortalTransparenciaPesquisaAcaoFavorecido.asp?Exercicio=2016&textoPesquisa=&textoPesquisaAcao=&codigoAcao=8442&codigoFuncao=08&siglaEstado=AC&codigoMunicipio=0105')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from pymongo import MongoClient\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "\n",
    "def read_city_page(city_page_url,municipio,estado,pagina):\n",
    "    cliente = MongoClient('localhost', 27017)\n",
    "\n",
    "    banco = cliente.projeto_final\n",
    "    projeto_transparencia = banco.test_collection\n",
    "    print ('read_city_page')\n",
    "    print (city_page_url)\n",
    "    city_page = urllib.request.urlopen(city_page_url)\n",
    "    city_page_soup = BeautifulSoup(city_page, \"lxml\", from_encoding='utf-8')\n",
    "\n",
    "    tables = city_page_soup.findAll(\"table\")\n",
    "    rows = tables[1].findAll(\"tr\")\n",
    "    header = rows[0]\n",
    "    #print ('header')\n",
    "    lista = []\n",
    "    json_pause = {}\n",
    "\n",
    "    nrows = len(rows)\n",
    "    for row in range(1,nrows):\n",
    "        linha = {}\n",
    "        cols = rows[row].findAll('td')\n",
    "        nis = cols[0].getText().strip()\n",
    "        nome = cols[1].getText().strip()\n",
    "        total = cols[2].getText().strip()\n",
    "        print (nome + ' - ' + nis + ' - ' + total)\n",
    "        person_url = base_url + cols[1].find('a').get('href')\n",
    "        valorTotal = cols[2].getText().strip()\n",
    "        js = read_person(person_url)\n",
    "        linha['Estado'] = estado\n",
    "        linha['Município'] = municipio\n",
    "        linha['Valores'] = js\n",
    "        linha['Nome'] = nome\n",
    "        linha['NIS'] = nis\n",
    "        linha['Total'] = float(total.replace(\".\",\"\").replace(\",00\",\"\"))\n",
    "        t = linha\n",
    "        verifica = read_json(estado,municipio,pagina,nis)\n",
    "        if verifica:\n",
    "            projeto_transparencia = banco.projeto_transparencia\n",
    "            a = projeto_transparencia.insert_one(t).inserted_id\n",
    "            lista.append(linha)\n",
    "            '''json_pause['Pagina'] = pagina\n",
    "            json_pause['Estado'] = estado\n",
    "            json_pause['Municipio'] = municipio\n",
    "            json_pause['Nome'] = nome\n",
    "            json_pause['Link'] = person_url \n",
    "            with open('teste_acrelandia.json', 'r') as arquivos:\n",
    "                a = json.loads(arquivos.read())\n",
    "            if linha['Nome'] != a['Nome']:\n",
    "                with open('teste_acrelandia.json', 'w') as arquivo:\n",
    "                    #arquivo.write(person_url)\n",
    "                    json.dump(json_pause, arquivo, indent=5, sort_keys=True)\n",
    "                projeto_transparencia = banco.projeto_transparencia\n",
    "                a = projeto_transparencia.insert_one(t).inserted_id\n",
    "                lista.append(linha)\n",
    "            else:\n",
    "                print ('Já salvo no bd')\n",
    "                #lista.append(linha) '''\n",
    "        else:\n",
    "            print ('Já salvo no bd')\n",
    "    \n",
    "    return lista\n",
    "                       \n",
    "#read_city_page('http://www.portaldatransparencia.gov.br/PortalTransparenciaPesquisaAcaoFavorecido.asp?Exercicio=2016&textoPesquisa=&textoPesquisaAcao=&codigoAcao=8442&codigoFuncao=08&siglaEstado=AC&codigoMunicipio=0643&Pagina=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_state_page(state_page_url,estado):\n",
    "    #print (state_page_url)\n",
    "    state_page = urllib.request.urlopen(state_page_url)\n",
    "    state_page_soup = BeautifulSoup(state_page, \"lxml\")\n",
    "    b = state_page_soup.findAll(\"td\", {\"class\":\"firstChild\"})\n",
    "    with open('teste_acrelandia.txt', 'r') as arquivo:\n",
    "        d = arquivo.read()\n",
    "    print (\"Munícipios já lidos \\n\" + d)\n",
    "    for td in state_page_soup.findAll(\"td\", {\"class\":\"firstChild\"}):\n",
    "        if td.a is not None:\n",
    "            #h = verifica_municipio(estado, td.a.getText())\n",
    "            #if h[\"Lido_Munia =cipio\"] != td.a.getText():\n",
    "                #print (h)\n",
    "            \n",
    "            if td.a.getText() not in d:\n",
    "                print (\"\\nESTOU AQUI \"+td.a.getText())\n",
    "                city_url = base_url + td.a.get('href')\n",
    "                print ('SOU O  city_url\\n'+ city_url)\n",
    "                read_city(city_url)\n",
    "                c = d  + td.a.getText() + \"\\n\"\n",
    "                with open('teste_acrelandia.txt', 'w') as arquivo:\n",
    "                    arquivo.write(c)\n",
    "    \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "def read_state(state_url,estado):\n",
    "    print (\"SOU O state_url\\n\" + state_url)\n",
    "    state_page = urllib.request.urlopen(state_url)\n",
    "    state_page_soup = BeautifulSoup(state_page, \"lxml\")\n",
    "    state_pagination = state_page_soup.find(id='paginacao').p.getText()\n",
    "    print(\"SOU O state_pagination\\n\"+state_pagination)\n",
    "    state_pages = str.split(state_pagination, '/')[1]\n",
    "    print (\"SOU O state_pages\\n\"+state_pages)\n",
    "    #state_pages = 1\n",
    "    for state_page in range(1,int(state_pages)+1):\n",
    "        state_page_url = state_url + '&Pagina=' + str(state_page)\n",
    "        print (\"SOU O state_page_url\\n\"+ state_page_url)\n",
    "        \n",
    "        read_state_page(state_page_url,estado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "main_url = 'http://www.portaldatransparencia.gov.br/PortalTransparenciaPesquisaAcaoUF.asp?codigoAcao=8442&codigoFuncao=08&NomeAcao=Transfer%EAncia+de+Renda+Diretamente+%E0s+Fam%EDlias+em+Condi%E7%E3o+de+Pobreza+e+Extrema+Pobreza+%28Lei+n%BA+10%2E836%2C+de+2004%29&Exercicio=2016'\n",
    "def read_main_page(main_url):\n",
    "    #print (main_page_url+\" ESTOU AQUI\")\n",
    "    main_page = urllib.request.urlopen(main_url)\n",
    "    main_page_soup = BeautifulSoup(main_page, \"lxml\")\n",
    "    a = main_page_soup.findAll(\"td\", {\"class\":\"firstChild\"})\n",
    "    print(len(a))\n",
    "    for td in main_page_soup.findAll(\"td\", {\"class\":\"firstChild\"}):\n",
    "        if td.a is not None:\n",
    "            print (td.a.getText())#printa o estado\n",
    "            state_url = base_url + td.a.get('href')\n",
    "            #print(state_url)\n",
    "            read_state(state_url,td.a.getText())\n",
    "\n",
    "def read_main(main_url):\n",
    "    main_page = urllib.request.urlopen(main_url)\n",
    "    soup = BeautifulSoup(main_page, \"lxml\")\n",
    "    pagination = soup.find(id='paginacao').p.getText()\n",
    "    print(pagination)  \n",
    "    pages = str.split(pagination, '/')[1]\n",
    "    print (pages)\n",
    "    for main_page in range(1,int(pages)+1):\n",
    "        main_page_url = main_url + '&Pagina=' + str(main_page)\n",
    "        print('eu sou o main_page_url \\n'+main_page_url)\n",
    "        read_main_page(main_page_url)\n",
    "        \n",
    "\n",
    "read_main(main_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
